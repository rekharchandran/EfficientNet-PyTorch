{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e06d00b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: efficientnet_pytorch in /home/stian/.local/lib/python3.8/site-packages (0.7.1)\n",
      "Requirement already satisfied: torch in /home/stian/.local/lib/python3.8/site-packages (from efficientnet_pytorch) (1.10.2+cu113)\n",
      "Requirement already satisfied: typing-extensions in /home/stian/.local/lib/python3.8/site-packages (from torch->efficientnet_pytorch) (4.0.1)\n"
     ]
    }
   ],
   "source": [
    "#!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd78a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import models, datasets\n",
    "from torchvision import transforms as T\n",
    "from glob import glob\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, Precision, Recall\n",
    "from ignite.handlers import LRScheduler, ModelCheckpoint, global_step_from_engine\n",
    "from ignite.contrib.handlers import ProgressBar, TensorboardLogger\n",
    "import ignite.contrib.engines.common as common\n",
    "from torch import optim, cuda\n",
    "\n",
    "#import opendatasets as od\n",
    "import os\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee25cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/storage/Projects/Fylkesveg/Sign_training_material/classification_training/'\n",
    "traindir = os.path.join(data_dir, 'train')\n",
    "validdir = os.path.join(data_dir, 'valid')\n",
    "testdir = os.path.join(data_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d1b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f087c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c034c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to display single or a batch of sample images\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "def show_batch(dataloader):\n",
    "    dataiter = iter(dataloader)\n",
    "    images, labels = dataiter.next()    \n",
    "    imshow(make_grid(images)) # Using Torchvision.utils make_grid function\n",
    "    \n",
    "def show_image(dataloader):\n",
    "    dataiter = iter(dataloader)\n",
    "    images, labels = dataiter.next()\n",
    "    random_num = randint(0, len(images)-1)\n",
    "    imshow(images[random_num])\n",
    "    label = labels[random_num]\n",
    "    print(f'Label: {label}, Shape: {images[random_num].shape}')\n",
    "\n",
    "# Setup function to create dataloaders for image datasets\n",
    "def generate_dataloader(data, name, transform):\n",
    "    if data is None: \n",
    "        return None\n",
    "    \n",
    "    # Read image files to pytorch dataset using ImageFolder, a generic data \n",
    "    # loader where images are in format root/label/filename\n",
    "    # See https://pytorch.org/vision/stable/datasets.html\n",
    "    if transform is None:\n",
    "        dataset = datasets.ImageFolder(data, transform=T.ToTensor())\n",
    "    else:\n",
    "        dataset = datasets.ImageFolder(data, transform=transform)\n",
    "\n",
    "    # Set options for device\n",
    "    if use_cuda:\n",
    "        kwargs = {\"pin_memory\": True, \"num_workers\": 0}\n",
    "    else:\n",
    "        kwargs = {}\n",
    "    \n",
    "    # Wrap image dataset (defined above) in dataloader \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, \n",
    "                        shuffle=(name==\"train\"), \n",
    "                        **kwargs)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organize Validation Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ef4fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation sequence for image pre-processing\n",
    "# If not using pre-trained model, normalize with 0.5, 0.5, 0.5 (mean and SD)\n",
    "# If using pre-trained ImageNet, normalize with mean=[0.485, 0.456, 0.406], \n",
    "# std=[0.229, 0.224, 0.225])\n",
    "preprocess_transform = T.Compose([\n",
    "                T.Resize(256), # Resize images to 256 x 256\n",
    "                T.CenterCrop(224), # Center crop image\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ToTensor(),  # Converting cropped images to tensors\n",
    "                # T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) # \n",
    "])\n",
    "\n",
    "preprocess_transform_pretrain = T.Compose([\n",
    "                T.Resize(256), # Resize images to 256 x 256\n",
    "                T.CenterCrop(224), # Center crop image\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ToTensor(),  # Converting cropped images to tensors\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6845d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = generate_dataloader(traindir, \"train\",\n",
    "                                  transform=preprocess_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741dbb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/storage/Projects/Fylkesveg/Sign_training_material/classification_training/'\n",
    "traindir = os.path.join(data_dir, 'train')\n",
    "validdir = os.path.join(data_dir, 'valid')\n",
    "testdir = os.path.join(data_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a9fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "train_data = torchvision.datasets.ImageFolder(root = '/storage/Projects/Fylkesveg/Sign_training_material/classification_training/train', transform = train_transforms)\n",
    "test_data = torchvision.datasets.ImageFolder(root = '/storage/Projects/Fylkesveg/Sign_training_material/classification_training/test', transform = test_transforms)\n",
    "dataloaders = data_loader(train_data,test_data , valid_size = 0.2 , batch_size = batch_size)\n",
    "#label of classes\n",
    "classes = train_data.classes\n",
    "#encoder and decoder to convert classes into integer\n",
    "decoder = {}\n",
    "for i in range(len(classes)):\n",
    "    decoder[classes[i]] = i\n",
    "encoder = {}\n",
    "for i in range(len(classes)):\n",
    "    encoder[i] = classes[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c20ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "#plotting rondom images from dataset\n",
    "def class_plot(data , encoder ,inv_normalize = None,n_figures = 12):\n",
    "    n_row = int(n_figures/4)\n",
    "    fig,axes = plt.subplots(figsize=(14, 10), nrows = n_row, ncols=4)\n",
    "    for ax in axes.flatten():\n",
    "        a = random.randint(0,len(data))\n",
    "        (image,label) = data[a]\n",
    "        print(type(image))\n",
    "        label = int(label)\n",
    "        l = encoder[label]\n",
    "        if(inv_normalize!=None):\n",
    "            image = inv_normalize(image)\n",
    "        \n",
    "        image = image.numpy().transpose(1,2,0)\n",
    "        im = ax.imshow(image)\n",
    "        ax.set_title(l)\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "class_plot(train_data,encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c2c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8139ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using efficientnet model based transfer learning\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.resnet =  EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.l1 = nn.Linear(1000 , 256)\n",
    "        self.dropout = nn.Dropout(0.75)\n",
    "        self.l2 = nn.Linear(256,6)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.resnet(input)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.dropout(self.relu(self.l1(x)))\n",
    "        x = self.l2(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "classifier = Classifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce33e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e965c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7305d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/davidtvs/pytorch-lr-finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd30f69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shutil.copy('./pytorch-lr-finder/lr_finder.py','./lr_finder.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4f04f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from lr_finder import LRFinder\n",
    "#optimizer_ft = optim.Adam(classifier.parameters(), lr=0.0000001)\n",
    "#lr_finder = LRFinder(classifier, optimizer_ft, criterion, device=device)\n",
    "#lr_finder.range_test(train_loader, end_lr=1, num_iter=500)\n",
    "#lr_finder.reset()\n",
    "#lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f03fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.zeros((128, 1, 128, 128))\n",
    "labels = torch.zeros((128, 128, 128))\n",
    "\n",
    "loss_fn = torch.nn.SmoothL1Loss()\n",
    "\n",
    "loss = loss_fn(pred.view(128, 128, 128), labels)\n",
    "\n",
    "loss.backward()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cac2ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,dataloaders,criterion,num_epochs=10,lr=0.00001,batch_size=8,patience = None):\n",
    "    since = time.time()\n",
    "    model.to(device)\n",
    "    best_acc = 0.0\n",
    "    i = 0\n",
    "    phase1 = dataloaders.keys()\n",
    "    losses = list()\n",
    "    acc = list()\n",
    "    if(patience!=None):\n",
    "        earlystop = EarlyStopping(patience = patience,verbose = True)\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch:',epoch)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        lr = lr*0.8\n",
    "        if(epoch%10==0):\n",
    "            lr = 0.0001\n",
    "\n",
    "        for phase in phase1:\n",
    "            if phase == ' train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            total = 0\n",
    "            j = 0\n",
    "            for  batch_idx, (data, target) in enumerate(dataloaders[phase]):\n",
    "                data, target = Variable(data), Variable(target)\n",
    "                data = data.type(torch.cuda.FloatTensor)\n",
    "                target = target.type(torch.cuda.LongTensor)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                _, preds = torch.max(output, 1)\n",
    "                running_corrects = running_corrects + torch.sum(preds == target.data)\n",
    "                running_loss += loss.item() * data.size(0)\n",
    "                j = j+1\n",
    "                if(phase =='train'):\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                if batch_idx % 300 == 0:\n",
    "                    print('{} Epoch: {}  [{}/{} ({:.0f}%)]\\tLoss: {:.6f} \\tAcc: {:.6f}'.format(phase,epoch, batch_idx * len(data), len(dataloaders[phase].dataset),100. * batch_idx / len(dataloaders[phase])\n",
    "                                                                                                 , running_loss/(j*batch_size),running_corrects.double()/(j*batch_size)))\n",
    "            epoch_acc = running_corrects.double()/(len(dataloaders[phase])*batch_size)\n",
    "            epoch_loss = running_loss/(len(dataloaders[phase])*batch_size)\n",
    "            if(phase == 'val'):\n",
    "                earlystop(epoch_loss,model)\n",
    "\n",
    "            if(phase == 'train'):\n",
    "                losses.append(epoch_loss)\n",
    "                acc.append(epoch_acc)\n",
    "            print(earlystop.early_stop)\n",
    "        if(earlystop.early_stop):\n",
    "            print(\"Early stopping\")\n",
    "            model.load_state_dict(torch.load('./checkpoint.pt'))\n",
    "            break\n",
    "        print('{} Accuracy: '.format(phase),epoch_acc.item())\n",
    "    return losses,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ad35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader):\n",
    "    running_corrects = 0\n",
    "    running_loss=0\n",
    "    pred = []\n",
    "    true = []\n",
    "    pred_wrong = []\n",
    "    true_wrong = []\n",
    "    image = []\n",
    "    sm = nn.Softmax(dim = 1)\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data = data.type(torch.cuda.FloatTensor)\n",
    "        target = target.type(torch.cuda.LongTensor)\n",
    "        classifier.eval()\n",
    "        output = classifier(data)\n",
    "        loss = criterion(output, target)\n",
    "        output = sm(output)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        running_corrects = running_corrects + torch.sum(preds == target.data)\n",
    "        running_loss += loss.item() * data.size(0)\n",
    "        preds = preds.cpu().numpy()\n",
    "        target = target.cpu().numpy()\n",
    "        preds = np.reshape(preds,(len(preds),1))\n",
    "        target = np.reshape(target,(len(preds),1))\n",
    "        data = data.cpu().numpy()\n",
    "        \n",
    "        for i in range(len(preds)):\n",
    "            pred.append(preds[i])\n",
    "            true.append(target[i])\n",
    "            if(preds[i]!=target[i]):\n",
    "                pred_wrong.append(preds[i])\n",
    "                true_wrong.append(target[i])\n",
    "                image.append(data[i])\n",
    "      \n",
    "    epoch_acc = running_corrects.double()/(len(dataloader)*batch_size)\n",
    "    epoch_loss = running_loss/(len(dataloader)*batch_size)\n",
    "    print(epoch_acc,epoch_loss)\n",
    "    return true,pred,image,true_wrong,pred_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597174a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_plot(loss):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(loss)\n",
    "    plt.title(\"Training loss plot\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "def acc_plot(acc):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(acc)\n",
    "    plt.title(\"Training accuracy plot\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.show()\n",
    "# To plot the wrong predictions given by model\n",
    "def wrong_plot(n_figures,true,ima,pred,encoder,inv_normalize):\n",
    "    print('Classes in order Actual and Predicted')\n",
    "    n_row = int(n_figures/3)\n",
    "    fig,axes = plt.subplots(figsize=(14, 10), nrows = n_row, ncols=3)\n",
    "    for ax in axes.flatten():\n",
    "        a = random.randint(0,len(true)-1)\n",
    "    \n",
    "        image,correct,wrong = ima[a],true[a],pred[a]\n",
    "        image = torch.from_numpy(image)\n",
    "        correct = int(correct)\n",
    "        c = encoder[correct]\n",
    "        wrong = int(wrong)\n",
    "        w = encoder[wrong]\n",
    "        f = 'A:'+c + ',' +'P:'+w\n",
    "        if inv_normalize !=None:\n",
    "            image = inv_normalize(image)\n",
    "        image = image.numpy().transpose(1,2,0)\n",
    "        im = ax.imshow(image)\n",
    "        ax.set_title(f)\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "def performance_matrix(true,pred):\n",
    "    precision = metrics.precision_score(true,pred,average='macro')\n",
    "    recall = metrics.recall_score(true,pred,average='macro')\n",
    "    accuracy = metrics.accuracy_score(true,pred)\n",
    "    f1_score = metrics.f1_score(true,pred,average='macro')\n",
    "    print('Precision: {} Recall: {}, Accuracy: {}: ,f1_score: {}'.format(precision*100,recall*100,accuracy*100,f1_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f6f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,dataloaders,criterion,num_epochs=50,lr=0.0001,batch_size=8,patience = None,classes = None):\n",
    "    dataloader_train = {}\n",
    "    losses = list()\n",
    "    accuracy = list()\n",
    "    key = dataloaders.keys()\n",
    "    for phase in key:\n",
    "        if(phase == 'test'):\n",
    "            perform_test = True\n",
    "        else:\n",
    "            dataloader_train.update([(phase,dataloaders[phase])])\n",
    "    losses,accuracy = train(model,dataloader_train,criterion,num_epochs,lr,batch_size,patience)\n",
    "    error_plot(losses)\n",
    "    acc_plot(accuracy)\n",
    "    if(perform_test == True):\n",
    "        true,pred,image,true_wrong,pred_wrong = test(dataloaders['test'])\n",
    "        wrong_plot(12,true_wrong,image,pred_wrong,encoder,inv_normalize)\n",
    "        performance_matrix(true,pred)\n",
    "        if(classes !=None):\n",
    "            plot_confusion_matrix(true, pred, classes= classes,title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23faef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(classifier,dataloaders,criterion,10, patience = 3 , batch_size = batch_size , classes = classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2ea580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a089d3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d174dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
